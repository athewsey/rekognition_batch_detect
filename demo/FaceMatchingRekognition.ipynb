{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2006f6",
   "metadata": {},
   "source": [
    "# Find Face Matches with Rekognition\n",
    "\n",
    "This Notebook is part of a demo designd to illustrate how to use the [face matching features](https://docs.aws.amazon.com/rekognition/latest/dg/collections.html) of [Amazon Rekognition](https://aws.amazon.com/rekognition/) to identify Matching Faces in a collection of photos.\n",
    "***\n",
    "***\n",
    "\n",
    "### Architecture\n",
    "![Demo Architecture](figures/FaceDuplicates-Page-3.png)\n",
    "\n",
    "***\n",
    "### Dataset\n",
    "\n",
    "For this demo the we use the [Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/)  dataset \\[1\\]. From the project website:\n",
    "> \\[...\\] a database of face photographs designed for studying the problem of unconstrained face recognition. The data set contains more than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured. 1680 of the people pictured have two or more distinct photos in the data set.\n",
    "\n",
    "\\[1\\] Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\n",
    "Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments.\n",
    "University of Massachusetts, Amherst, Technical Report 07-49, October, 2007."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a019a8",
   "metadata": {},
   "source": [
    "### Prepare the environment\n",
    "To ensure all the necessary python libraries are installed, make sure to pip-install the `requirements.txt` file in the same environment as the kernel of this notebook.\n",
    "\n",
    "```terminal\n",
    "~$ pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import awswrangler as wr\n",
    "import boto3\n",
    "import s3fs\n",
    "\n",
    "from utils import count_hits, inspect_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775d019",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be67ec",
   "metadata": {},
   "source": [
    "We download the compressed archive containing all the images in the dataset from the project website, and unpack it to the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300070d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_source = \"http://vis-www.cs.umass.edu/lfw/lfw.tgz\"\n",
    "!wget -nc {images_source}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa4989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path_local = Path(\"data/lfw/\")\n",
    "if images_path_local.exists() is False:\n",
    "    shutil.unpack_archive(\"lfw.tgz\", \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edebe6",
   "metadata": {},
   "source": [
    "The photos are organized by people, and for some people there are multiple photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path_local = Path(\"data/lfw/\")\n",
    "\n",
    "# !tree {images_path_local}  > data_tree.txt\n",
    "with open(\"data_tree.txt\") as f:\n",
    "    a = \"\".join([f.readline() for _ in range(15)] + [\"...\"])\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c1f242",
   "metadata": {},
   "source": [
    "## Add faces to the Rekognition collection\n",
    "\n",
    "We can add faces to the Rekognition collection by PUTting image files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm = boto3.client(\"ssm\")\n",
    "rekognition = boto3.client(\"rekognition\")\n",
    "\n",
    "s3 = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c41479",
   "metadata": {},
   "source": [
    "The demo template stores the S3 bucket name and the name of the pre-created Rekognition collection in AWS Systems Manager Paramter Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d168f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_name = \"RekognitionBatchDetect\"\n",
    "images_bucket_name = ssm.get_parameters(Names=[f\"/{stack_name}/ImageBucket\"])[\n",
    "    \"Parameters\"\n",
    "][0][\"Value\"]\n",
    "output_bucket_name = ssm.get_parameters(Names=[f\"/{stack_name}/OutBucket\"])[\n",
    "    \"Parameters\"\n",
    "][0][\"Value\"]\n",
    "collection_id = ssm.get_parameters(Names=[f\"/{stack_name}/CollectionId\"])[\"Parameters\"][\n",
    "    0\n",
    "][\"Value\"]\n",
    "\n",
    "print(\n",
    "    f\"Collection ID: {collection_id}\\nImages Bucket: {images_bucket_name}\\nOutput Bucket: {output_bucket_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc22af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_faces_collection = len(rekognition.list_faces(CollectionId=collection_id)[\"Faces\"])\n",
    "print(f\"There are currently {n_faces_collection} in the {collection_id} collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e0a7a8",
   "metadata": {},
   "source": [
    "### Upload files\n",
    "In order to observe the dynamics of the collection and the matching mechanism and notifications, we upload images\n",
    "by initial letter.\n",
    "\n",
    "This step can be repeated (possibly changing letter at every iteration), to observe and validate the operation of the lambda function and the notification settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_initial = \"C\"  # replace with any capital letter of the English alphabet\n",
    "n_upload = len(list(images_path_local.glob(name_initial + \"*\")))\n",
    "\n",
    "print(f\"We are going to upload {n_upload} images to the S3 bucket {images_bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd4d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = s3.put(\n",
    "    f\"data/lfw/{name_initial}*\", f\"s3://{images_bucket_name}/images/\", recursive=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcfde89-17bf-4d81-a772-9f6958ea92d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_faces_collection = len(rekognition.list_faces(CollectionId=collection_id)[\"Faces\"])\n",
    "print(f\"There are currently {n_faces_collection} in the {collection_id} collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138b13b1",
   "metadata": {},
   "source": [
    "## Check results\n",
    "\n",
    "To check the results we need to parse the reports uploaded to the `output_bucket` as `json` files. To make the analysis more accessible, we will use the AWS Glue catalog and the Athena table and view created by the template.\n",
    "\n",
    "For this demonstration, we will read the tables into Pandas dataframes for ease of manipulation. This approach is valid for datasets of few thousands of records, but for larger sets of data an Amazon Quicksight dashboard is a more robust and salable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe05c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"face_match_output_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e0b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Glue catalog ready!\"\n",
    "if db_name not in wr.catalog.databases().values:\n",
    "    message = \"Check that the template is fully deployed\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feacdc2",
   "metadata": {},
   "source": [
    "There should be two tables in the database:\n",
    "- `face_match_output`: obtained by queriying the output reports directly\n",
    "- `matchingstats`: unnest the array of matches for entries with at least one match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462136bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.catalog.tables(database=db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reports = wr.athena.read_sql_query(\n",
    "    \"SELECT source, customerid FROM face_match_output\",\n",
    "    database=db_name,\n",
    "    ctas_approach=False,\n",
    ")\n",
    "\n",
    "# The matches column is a `ROW` format that doesn't play well with pandas,\n",
    "# better exclude it and unwrap it using a view in Athena\n",
    "df_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1031c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches = wr.athena.read_sql_query(\n",
    "    \"SELECT * FROM matchingstats\", database=db_name, ctas_approach=False\n",
    ")\n",
    "print(f\"There are a total of {len(df_matches)} matches\")\n",
    "df_matches.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4879f092",
   "metadata": {},
   "source": [
    "We can look into the distribution of the similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df_matches.similarity.hist(bins=25, figsize=(14, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0973528",
   "metadata": {},
   "source": [
    "But this histogram can be polluted by occurences of legitimate similarities. Probalby more interesting to look into the max similarity for each pair of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429927aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = (\n",
    "    df_matches.groupby([\"customerid\", \"suspect_match\"])\n",
    "    .max()\n",
    "    .hist(bins=25, figsize=(14, 8))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26173f6d",
   "metadata": {},
   "source": [
    "And check how many images are a suspected match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58300498",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = (\n",
    "    df_matches.groupby([\"customerid\", \"suspect_match\"])\n",
    "    .count()\n",
    "    .sort_values(\"similarity\")\n",
    "    .rename(columns={\"similarity\": \"# of Matches\"})\n",
    "    .plot.barh(figsize=(14, 18))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585839fd-422e-46c8-983d-1ba5c002bb33",
   "metadata": {},
   "source": [
    "To cleanup the results it's a good idea to set a minimum similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77740a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 95\n",
    "_ = (\n",
    "    df_matches.groupby(\n",
    "        [\"customerid\", \"suspect_match\", (df_matches.similarity > threshold)]\n",
    "    )\n",
    "    .count()\n",
    "    .rename(columns={\"similarity\": \"# of Matches\"})\n",
    "    .sort_values([\"# of Matches\"])\n",
    "    .unstack(level=-1)\n",
    "    .plot.barh(\n",
    "        figsize=(14, 18),\n",
    "        subplots=True,\n",
    "        sharey=True,\n",
    "        sharex=False,\n",
    "        layout=(1, 2),\n",
    "        title=[f\"Similarity below {threshold}\", f\"Similarity above {threshold}\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8249bf1d",
   "metadata": {},
   "source": [
    "### Check duplicates\n",
    "We can look in detail into one of the cases identified, and look into the images themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb2a0cd-b352-4bf6-a44d-faae1ced2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_of_interest = (\n",
    "    df_matches[df_matches.similarity > threshold]\n",
    "    .groupby([\"customerid\", \"suspect_match\"])\n",
    "    .max()\n",
    ")\n",
    "cases_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66757820",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_check = cases_of_interest.sample(1).index[0][0]\n",
    "\n",
    "name_list = s3.glob(f\"{output_bucket_name}/output/{name_to_check}*\")\n",
    "duplicate_list = [k for k in name_list if count_hits(k) > 0]\n",
    "\n",
    "print(\n",
    "    f\"We will check {name_to_check}, in particular, these maching records\\n{duplicate_list}\\n\\n\"\n",
    "    \"An example of the structure of the match record:\"\n",
    ")\n",
    "with s3.open(duplicate_list[0]) as f:\n",
    "    example = json.load(f)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b08a735-884e-4b28-b2da-e7cafd356a35",
   "metadata": {},
   "source": [
    "We can now inspect the matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2a9ad-3eb7-46d6-ae96-0928a7d8ead7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inspect_matches(images_bucket_name, duplicate_list[0])"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "598211af94c03e037ee823b1ee303813be766d4750cf0422f1cb56e78483f641"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "sagemaker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
